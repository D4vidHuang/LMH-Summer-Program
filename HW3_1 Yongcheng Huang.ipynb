{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "“HW3_1.ipynb”的副本",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Perform MNIST classification using Neural Netwroks and Convolutional Neural Networks.\n",
    "\n",
    "1) Use 10 iterations for training\n",
    "\n",
    "\n",
    "2) Show the training loss for both networks on the same plot\n",
    "\n",
    "\n",
    "3) Compare the test loss and accuracy."
   ],
   "metadata": {
    "id": "e_mMw1jKdhNI",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\r\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 5.9 MB 5.6 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (3.19.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.27.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (61.2.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.42.0)\r\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\r\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (3.3.4)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.21.5)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.33.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.37.1)\r\n",
      "Collecting absl-py>=0.4\r\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 123 kB 33.7 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting tensorboard-plugin-wit>=1.6.0\r\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 781 kB 17.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\r\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 3.5 MB 30.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.0.3)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\r\n",
      "Collecting requests-oauthlib>=0.7.0\r\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yongcheng/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\r\n",
      "Collecting oauthlib>=3.0.0\r\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 151 kB 17.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hInstalling collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, tensorboard\r\n",
      "Successfully installed absl-py-1.2.0 google-auth-oauthlib-0.4.6 oauthlib-3.2.0 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FD6fwO1ddbEU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#preparations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models,transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "# MNIST\n",
    "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
    "    num_classes = 10\n",
    "    transform_train = transforms.Compose([\n",
    "                        transforms.RandomCrop(28, padding=4),\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_valid = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "\n",
    "    # Training dataset\n",
    "    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n",
    "    valid_data = MNIST(root='./datasets', train=True, download=True, transform=transform_valid)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz, sampler=train_sampler,pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_sz, sampler=valid_sampler,pin_memory=True)\n",
    "\n",
    "    # Test dataset\n",
    "    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
    "train_loader, valid_loader, test_loader=mnist(batch_sz) "
   ],
   "metadata": {
    "id": "8fthqzfQoCjt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 10, 5, 1)\n",
    "      self.conv2 = nn.Conv2d(10, 50, 5, 1)\n",
    "      self.linear1 = nn.Linear(4 * 4 * 50, 100)\n",
    "      self.linear2 = nn.Linear(100, 10)\n",
    "      self.maxpool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    #feature extracter\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "\n",
    "    x = x.view(-1, 4*4*50)\n",
    "\n",
    "    #classifier\n",
    "    x = self.linear1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.linear2(x)\n",
    "    return(x)"
   ],
   "metadata": {
    "id": "ne1lMu2noEWx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NN(nn.Module):\n",
    "  def __init__(self, ni, nh, no):\n",
    "    super().__init__()\n",
    "    self.l1 = nn.Linear(ni, nh)\n",
    "    self.l2 = nn.Linear(nh, no)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, 28*28)\n",
    "    x = self.l1(x)\n",
    "    x = torch.sigmoid(x)\n",
    "    x = self.l2(x)\n",
    "    return x\n",
    "\n",
    "ni = 28*28\n",
    "nh = 100\n",
    "no = 10\n",
    "\n",
    "lr1 = 0.5\n",
    "mm1 = 0.5\n",
    "epochs1 = 10\n",
    "\n",
    "ls1 = []\n",
    "\n",
    "device1 = torch.device(\"cuda:0\")\n",
    "net1 = NN(ni, nh, no)\n",
    "net1 = net1.to(device1)\n",
    "\n",
    "optimizer = optim.SGD(net1.parameters(), lr = lr1, momentum = mm1)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    " \n",
    "for i in range(epochs1):\n",
    "  total_loss = 0\n",
    "  for batch in train_loader:\n",
    "    X, y = batch[0].to(device1), batch[1].to(device1)\n",
    "    logits = net1(X)\n",
    "    loss = loss_fn(logits, y)\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  ls1.append(total_loss)\n"
   ],
   "metadata": {
    "id": "RkyR-6t5p7uK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 26>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     24\u001B[0m device1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m net1 \u001B[38;5;241m=\u001B[39m NN(ni, nh, no)\n\u001B[0;32m---> 26\u001B[0m net1 \u001B[38;5;241m=\u001B[39m \u001B[43mnet1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mSGD(net1\u001B[38;5;241m.\u001B[39mparameters(), lr \u001B[38;5;241m=\u001B[39m lr1, momentum \u001B[38;5;241m=\u001B[39m mm1)\n\u001B[1;32m     30\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    923\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    924\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m    925\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m--> 927\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 579\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    581\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    583\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    584\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    589\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    590\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 602\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    603\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m    923\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    924\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m--> 925\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:211\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    208\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    209\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 211\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    214\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = CNN()\n",
    "net = net.to(device)\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "mm = 0.5\n",
    "\n",
    "ls = []\n",
    "optimizer = optim.SGD(net.parameters(), lr = lr, momentum = mm)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.9, verbose = False)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(epochs):\n",
    "  total_loss = 0\n",
    "  for batch in train_loader:\n",
    "    X, y = batch[0].to(device),batch[1].to(device)\n",
    "    logits = net(X)\n",
    "    loss = loss_fn(logits, y)\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  scheduler.step()\n",
    "  ls.append(total_loss)\n"
   ],
   "metadata": {
    "id": "teziFfTYoWTS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(ls1)\n",
    "plt.plot(ls)"
   ],
   "metadata": {
    "id": "AIlDHBE2sxiD",
    "outputId": "1b1e09aa-b8d6-497e-9f72-15ef57e1f54a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The picture above shows the total loss of NN and CNN."
   ],
   "metadata": {
    "id": "pVEHml_bw1vq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"The loss of NN:\")\n",
    "print(ls1)\n",
    "print(\"The loss of CNN:\")\n",
    "print(ls)"
   ],
   "metadata": {
    "id": "TfhKxVL0xQvE",
    "outputId": "108e3534-cfdc-48cb-ebd7-df687f51b268",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the data above we can see the loss of CNN is much better than NN."
   ],
   "metadata": {
    "id": "chGHq_pSxazV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchmetrics"
   ],
   "metadata": {
    "id": "Ul_7ju-Qx845",
    "outputId": "cda99245-696c-444e-e057-3f80bc1a8d06",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchmetrics as tm\n",
    "acc1 = []\n",
    "accuracy1 = tm.Accuracy()\n",
    "for batch in test_loader:\n",
    "  X, y = batch[0].to(device), batch[1].to(device)\n",
    "  logits = net1(X)\n",
    "  yhat = torch.argmax(logits, axis = 1)\n",
    "  a = accuracy1(yhat.to(\"cpu\"), y.to(\"cpu\"))\n",
    "  acc1.append(a)\n",
    "\n",
    "plt.plot(acc1)\n",
    "print(np.mean(acc1))\n",
    "plt.figure()\n",
    "acc = []\n",
    "accuracy = tm.Accuracy()\n",
    "for batch in test_loader:\n",
    "  X, y = batch[0].to(device), batch[1].to(device)\n",
    "  logits = net(X)\n",
    "  yhat = torch.argmax(logits, axis = 1)\n",
    "  a = accuracy(yhat.to(\"cpu\"), y.to(\"cpu\"))\n",
    "  acc.append(a)\n",
    "\n",
    "plt.plot(acc)\n",
    "print(np.mean(acc))\n",
    "plt.figure()\n"
   ],
   "metadata": {
    "id": "kAYlEW_9xtV7",
    "outputId": "8b7f22f6-1a55-46f1-93ba-d7d4b9b5e875",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the data above we can conclude that CNN has a better accuracy than NN."
   ],
   "metadata": {
    "id": "iLUpWAcczB6K",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}